{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d75e751",
   "metadata": {},
   "source": [
    "<H1>Linear Tree Algorithm experiment</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fefa4",
   "metadata": {},
   "source": [
    "1.) Collect, clean exemplary dataset for regression problem suited for linear tree model.<br>\n",
    "2.) Develop single tree algorithm with variables for depth, omitted features as input (others to be added later) and feature importance and classification solution as output<br>\n",
    "3.) Define simple Gradient Boosting algorithm<br>\n",
    "4.) Bring full algorithm together<br>\n",
    "5.) Run tests with exemplary dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc50f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly as pl\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6232e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning and pre-preparation completed in EDA module\n",
    "df=pd.read_csv('data/ames_housing_price_data_prepared_v01.csv')\n",
    "df['SalePriceLog']=np.log10(df['SalePrice'])\n",
    "df=df.drop(['Unnamed: 0','SalePrice'],axis=1)\n",
    "\n",
    "#price=df['SalePrice']\n",
    "#price_log = np.log10(price)\n",
    "#df.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d50c2f",
   "metadata": {},
   "source": [
    "<H1>Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f2d4e",
   "metadata": {},
   "source": [
    "'''\n",
    "keep: feature importance dictionary (key: feature, val: total RSS delta through feature split)\n",
    "keep: dataframe split into subtrees (through extra column identifying the subtree_id\n",
    "Input: (dictionary of used subtree_ids(increasing), including a tuple of splitting variable, splitting position, current maxdepth, subtree_id it was split from), same dict, but for unused subtrees, current RSS\n",
    "for each subtree\n",
    "    if not yet at maxdepth\n",
    "    check if split was searched before in unused subtree dict\n",
    "    for each feature\n",
    "        for each gap between two observations\n",
    "            divide tree into two subtrees\n",
    "            run linar regression on each subtree\n",
    "            save tuple: (feature, gapposition, RSS-delta)\n",
    "    find tuple with max RSS-delta, discard remaining tuples\n",
    "find remaining tuple with max RSS-delta\n",
    "split dataframe, update dictionaries, update feature importance dictionary with RSS delta\n",
    "if all subtrees at maxdepth: return RSS, (how to return splitting logic??)\n",
    "else: feed dataframes, RSS current-delta, list of maxdepth per subtree into next tree\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd42d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeBooster():\n",
    "    \n",
    "    def __init__(self, n_iter=16, n_iterations=10, learning_rate=0.1, max_depth=6, min_elements=1,alpha=1):\n",
    "        self.n_iter=n_iter\n",
    "        self.n_iterations=n_iterations\n",
    "        self.learning_rate=learning_rate\n",
    "        self.max_depth=max_depth\n",
    "        self.min_elements=min_elements\n",
    "        self.alpha=alpha\n",
    "        self.split_conditions={}\n",
    "        self.tree_means={}\n",
    "        self.tree_depth={}\n",
    "        self.columns=[]\n",
    "        \n",
    "        self.initial_mean=0\n",
    "        \n",
    "    \n",
    "    def check_error(self,df):\n",
    "        #extract y and x columns and relevant rows for split (2x)\n",
    "        #Run RidgeRegression fit and score for each\n",
    "        #RidgeRegressionScore as new error\n",
    "        \n",
    "        #Ridge solution: ùõΩ=(ùëãùëáùëã+ùúÜùêº)‚àí1ùëãùëáùë¶.\n",
    "\n",
    "        onerow=np.ones(df.shape[0]).reshape(df.shape[0],1)\n",
    "        X_vals=np.c_[onerow,np.matrix(df[columns])]\n",
    "        Y_vals=np.matrix(df['Residuals'])\n",
    "        Identity=np.eye(X_vals.shape[1])\n",
    "        Identity[0,0]=0\n",
    "\n",
    "        coefs=(X_vals.T.dot(X_vals)+self.alpha*Identity).I.dot(X_vals.T).dot(Y_vals.T)\n",
    "        \n",
    "        error=sum(df.apply(lambda x: (x['Residuals']-(np.matrix(x[columns])*coefs[1:]+coefs[0]))**2, axis=1))/df.shape[0]\n",
    "        return error\n",
    "\n",
    "    def treebuilder(self, df, tree_num=0):\n",
    "\n",
    "        df['subtree_id']=0\n",
    "        #feature_importance_dict={}\n",
    "        max_subtree_id=0\n",
    "\n",
    "        tmp_dict={}\n",
    "        self.split_conditions[tree_num]={}\n",
    "        self.tree_means[tree_num]={}\n",
    "        self.tree_depth[tree_num]={}\n",
    "        \n",
    "        self.tree_depth[tree_num][0]=0\n",
    "\n",
    "        k=0\n",
    "        while k<self.n_iter:\n",
    "\n",
    "            subtree_ids=df['subtree_id'].unique()\n",
    "\n",
    "            for subtree_id in subtree_ids: #each current subtree\n",
    "                \n",
    "                if self.tree_depth[tree_num][subtree_id]<self.max_depth:\n",
    "                    \n",
    "                    currentError=self.check_error(df[df['subtree_id']==subtree_id])\n",
    "                    \n",
    "                    for column in self.columns:#each feature\n",
    "\n",
    "                        if (subtree_id,column) not in tmp_dict:\n",
    "\n",
    "                            split_values=list(df[df['subtree_id']==subtree_id][column].unique())\n",
    "                            split_values.sort()\n",
    "                            split_val=[]\n",
    "                            for i in range(1, len(split_values)):\n",
    "                                split_val.append(split_values[i-1]+(split_values[i]-split_values[i-1])/2)\n",
    "\n",
    "                            maxError=0\n",
    "                            for i in split_val:#each split\n",
    "                                \n",
    "                                bottom_shape=df[(df['subtree_id']==subtree_id) & (df[column]<i)].shape[0]\n",
    "                                top_shape=df[(df['subtree_id']==subtree_id) & (df[column]>=i)].shape[0]\n",
    "                                total_shape=df[(df['subtree_id']==subtree_id)].shape[0]\n",
    "                                \n",
    "                                if bottom_shape>=self.min_elements and top_shape>=self.min_elements:\n",
    "                                    \n",
    "                                    newError=(self.check_error(df[(df['subtree_id']==subtree_id) & (df[column]<i)])*bottom_shape + self.check_error(df[(df['subtree_id']==subtree_id) & (df[column]>=i)])*top_shape)/total_shape\n",
    "\n",
    "                                    deltaError=currentError-newError\n",
    "\n",
    "                                    if deltaError>maxError:\n",
    "                                        tmp_dict[(subtree_id,column)]=(i,deltaError)\n",
    "                                        maxError=deltaError\n",
    "\n",
    "            #print(tmp_dict)\n",
    "            if tmp_dict:\n",
    "                best_subtree_id, best_column=max(tmp_dict, key=lambda x: tmp_dict.get(x)[1])\n",
    "                best_split_pos=tmp_dict[(best_subtree_id, best_column)][0]\n",
    "                max_subtree_id+=1\n",
    "                df.loc[(df['subtree_id']==best_subtree_id) & (df[best_column]<best_split_pos),'subtree_id']=max_subtree_id\n",
    "                self.tree_depth[tree_num][max_subtree_id]=self.tree_depth[tree_num][best_subtree_id]+1\n",
    "                max_subtree_id+=1\n",
    "                df.loc[(df['subtree_id']==best_subtree_id)&(df[best_column]>=best_split_pos),'subtree_id']=max_subtree_id\n",
    "                self.tree_depth[tree_num][max_subtree_id]=self.tree_depth[tree_num][best_subtree_id]+1\n",
    "\n",
    "                for i,j in list(tmp_dict.keys()):\n",
    "                    if i==best_subtree_id:\n",
    "                        del tmp_dict[(i,j)]   \n",
    "                        \n",
    "                        \n",
    "                self.split_conditions[tree_num][best_subtree_id]=(best_column,best_split_pos,max_subtree_id-1,max_subtree_id)\n",
    "            \n",
    "            k+=1\n",
    "            \n",
    "            #print(df['subtree_id'].value_counts())\n",
    "\n",
    "        \n",
    "        subtree_ids=df['subtree_id'].unique()\n",
    "        for subtree_id in subtree_ids: #each subtree\n",
    "            mean=df[df['subtree_id']==subtree_id]['Residuals'].mean()\n",
    "            self.tree_means[tree_num][subtree_id]=mean\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def tree_predictor(self, df, tree_num=0):\n",
    "        \n",
    "        df['Predict']=0\n",
    "        for i in df.index:\n",
    "            current_subtree_id=0\n",
    "            while current_subtree_id not in self.tree_means[tree_num]:\n",
    "                column,split_pos,id_left,id_right = self.split_conditions[tree_num][current_subtree_id]\n",
    "                if df[column][i]<split_pos:\n",
    "                    current_subtree_id=id_left\n",
    "                else:\n",
    "                    current_subtree_id=id_right\n",
    "            df.loc[i,'Predict']=self.tree_means[tree_num][current_subtree_id]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def tree_scorer(self,df):\n",
    "        mean1=sum(df.iloc[:,0])/df.shape[0]\n",
    "        TSS=sum(df.iloc[:,0].map(lambda x: (x-mean1)**2))\n",
    "\n",
    "        RSS=sum((df.iloc[:,1]-df.iloc[:,0])**2)\n",
    "\n",
    "        return 1-RSS/TSS\n",
    "\n",
    "\n",
    "    def iteration_builder(self, df):\n",
    "        df2=df.copy()\n",
    "        #df2.reset_index(drop=True)\n",
    "        \n",
    "        self.columns=list(df2.columns)\n",
    "        self.columns.pop()\n",
    "        \n",
    "        df2['Base_prediction']=df2['SalePriceLog'].mean()\n",
    "        self.initial_mean=df2['SalePriceLog'].mean()\n",
    "        df2['Residuals']=df2['SalePriceLog']-df2['Base_prediction']\n",
    "        \n",
    "        res_mean=df2['Residuals'].mean()\n",
    "        print(f'Starting; residual mean at {res_mean}')\n",
    "        \n",
    "        for x in range(self.n_iterations):\n",
    "            df2=self.treebuilder(df2,tree_num=x)\n",
    "            df2=self.tree_predictor(df2,tree_num=x)\n",
    "            df2['Base_prediction']=df2['Base_prediction']+df2['Predict']*self.learning_rate\n",
    "            df2['Residuals']=df2['SalePriceLog']-df2['Base_prediction']\n",
    "            df2=df2.drop(['Predict'],axis=1)\n",
    "            \n",
    "            res_mean=df2['Residuals'].mean()\n",
    "            print(f'Iteration {x} complete, residual mean at {res_mean}')\n",
    "        return df2\n",
    "    \n",
    "    def iteration_predictor(self, df):\n",
    "        \n",
    "        df2=df.copy()\n",
    "        df2=df2.reset_index(drop=False)\n",
    "\n",
    "        df2['Predict_fin']=self.initial_mean\n",
    "        for x in range(self.n_iterations):\n",
    "            df2=self.tree_predictor(df2,tree_num=x)\n",
    "            df2['Predict_fin']=df2['Predict_fin']+self.learning_rate*df2['Predict']\n",
    "            \n",
    "        df2['Predict']=df2['Predict_fin']\n",
    "        df2=df2.drop('Predict_fin',axis=1)\n",
    "        \n",
    "        df2=df2.set_index('index',drop=True)\n",
    "        df2.index.name=None\n",
    "\n",
    "        return df2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8899fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices=list(np.random.choice(df.index, size=int(df.shape[0]*0.7),replace=False))\n",
    "test_indices=[x if x not in train_indices else -1 for x in df.index]\n",
    "df_train=df.loc[df.index.isin(train_indices)]\n",
    "df_test=df.loc[df.index.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "875368b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting; residual mean at 1.3717652030455834e-14\n",
      "Iteration 0 complete, residual mean at 1.1125494523833933e-14\n",
      "Iteration 1 complete, residual mean at 8.997071617020535e-15\n",
      "Iteration 2 complete, residual mean at 7.163329559583781e-15\n",
      "Iteration 3 complete, residual mean at 5.64908358094486e-15\n",
      "Iteration 4 complete, residual mean at 4.347318004224885e-15\n",
      "Iteration 5 complete, residual mean at 3.4875737015698747e-15\n",
      "Iteration 6 complete, residual mean at 2.698656199554513e-15\n",
      "Iteration 7 complete, residual mean at 2.059147058012572e-15\n",
      "Iteration 8 complete, residual mean at 1.5933445224189674e-15\n",
      "Iteration 9 complete, residual mean at 1.2728144757285847e-15\n",
      "Iteration 10 complete, residual mean at 1.0742926403590572e-15\n",
      "Iteration 11 complete, residual mean at 8.773217568283542e-16\n",
      "Iteration 12 complete, residual mean at 5.08712203134414e-16\n",
      "Iteration 13 complete, residual mean at 3.288017898307798e-16\n",
      "Iteration 14 complete, residual mean at 3.6033781055354326e-16\n",
      "Iteration 15 complete, residual mean at 2.326427758236649e-16\n"
     ]
    }
   ],
   "source": [
    "treemodel=TreeBooster(n_iter=12, n_iterations=16, learning_rate=0.2, max_depth=4, min_elements=5,alpha=1)\n",
    "df_train= treemodel.iteration_builder(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b97fc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9024810993000432"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=df_test.reset_index(drop=False)\n",
    "df_test2=treemodel.iteration_predictor(df_test)\n",
    "treemodel.tree_scorer(df_test2[['SalePriceLog','Predict']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "64bd60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(df.columns)\n",
    "columns.pop()\n",
    "\n",
    "#Ridge solution: ùõΩ=(ùëãùëáùëã+ùúÜùêº)‚àí1ùëãùëáùë¶.\n",
    "\n",
    "alpha=5\n",
    "\n",
    "onerow=np.ones(df.shape[0]).reshape(df.shape[0],1)\n",
    "X_vals=np.c_[onerow,np.matrix(df[columns])]\n",
    "Y_vals=np.matrix(df['SalePriceLog'])\n",
    "Identity=np.eye(X_vals.shape[1])\n",
    "Identity[0,0]=0\n",
    "\n",
    "coefs=(X_vals.T.dot(X_vals)+alpha*Identity).I.dot(X_vals.T).dot(Y_vals.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc44060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0e7426a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5.06988387]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix(df[columns].iloc[0])*coefs[1:]+coefs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9f3b9832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.00167333]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.apply(lambda x: (x['SalePriceLog']-(np.matrix(x[columns])*coefs[1:]+coefs[0]))**2, axis=1))/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "700c388d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 4.84707792e+00],\n",
       "        [ 1.25709774e-04],\n",
       "        [ 9.52299652e-07],\n",
       "        [ 2.63177651e-01],\n",
       "        [ 5.38010471e-05],\n",
       "        [-1.33832592e-03],\n",
       "        [ 2.08744203e-02],\n",
       "        [ 2.61102361e-03],\n",
       "        [ 5.23383141e-03],\n",
       "        [ 7.25253877e-03],\n",
       "        [ 1.77698455e-02],\n",
       "        [ 6.30631294e-05],\n",
       "        [ 9.40928090e-05],\n",
       "        [ 1.30058882e-02],\n",
       "        [-1.48881599e-03],\n",
       "        [-2.26297306e-03],\n",
       "        [ 2.98398898e-04],\n",
       "        [-8.87426585e-03],\n",
       "        [ 5.26773929e-03],\n",
       "        [ 3.35403279e-03],\n",
       "        [ 1.25040847e-02],\n",
       "        [ 4.02121256e-04],\n",
       "        [-1.15841079e-02],\n",
       "        [-2.24948118e-03],\n",
       "        [-4.66425057e-03],\n",
       "        [ 5.42355744e-04],\n",
       "        [-1.01228680e-03],\n",
       "        [-1.11186005e-02],\n",
       "        [-1.87518680e-03],\n",
       "        [ 7.45129054e-03],\n",
       "        [ 3.06570978e-02],\n",
       "        [-1.76349982e-03],\n",
       "        [-1.59760567e-03],\n",
       "        [ 1.10901976e-01],\n",
       "        [ 2.37664799e-02],\n",
       "        [ 2.69660120e-03],\n",
       "        [-1.99343940e-02],\n",
       "        [-6.46449328e-03],\n",
       "        [ 1.10764462e-02],\n",
       "        [ 9.02060945e-03],\n",
       "        [ 5.54222288e-02],\n",
       "        [-2.15987007e-02],\n",
       "        [-7.66938840e-03],\n",
       "        [ 1.48118809e-02],\n",
       "        [ 0.00000000e+00],\n",
       "        [-1.36573585e-02],\n",
       "        [ 0.00000000e+00],\n",
       "        [-5.18776513e-02],\n",
       "        [ 1.31717701e-03],\n",
       "        [ 3.96490682e-03],\n",
       "        [ 3.11500558e-03],\n",
       "        [-9.98011339e-03],\n",
       "        [ 2.59256968e-03],\n",
       "        [ 2.88078205e-02],\n",
       "        [-1.86429778e-02],\n",
       "        [-9.54958572e-03],\n",
       "        [-1.26664514e-02],\n",
       "        [-1.95632020e-02],\n",
       "        [ 2.49339042e-02],\n",
       "        [ 3.84650591e-02],\n",
       "        [ 1.93840289e-02],\n",
       "        [-6.93245311e-03],\n",
       "        [-2.40132790e-02],\n",
       "        [-5.51810433e-02],\n",
       "        [-5.01634507e-02],\n",
       "        [-2.32651109e-02],\n",
       "        [-2.03800610e-03],\n",
       "        [ 3.84594738e-04]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error=sum(df['Residuals'].apply(lambda x: (x-mean)**2))/df.shape[0]\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d32986de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge=Ridge(alpha=5)\n",
    "ridge.fit(X_vals,Y_vals.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c3e9da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.84707792])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c994352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
