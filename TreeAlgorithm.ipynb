{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d75e751",
   "metadata": {},
   "source": [
    "<H1>Linear Tree Algorithm experiment</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fefa4",
   "metadata": {},
   "source": [
    "1.) Collect, clean exemplary dataset for regression problem suited for linear tree model.<br>\n",
    "2.) Develop single tree algorithm with variables for depth, omitted features as input (others to be added later) and feature importance and classification solution as output<br>\n",
    "3.) Define simple Gradient Boosting algorithm<br>\n",
    "4.) Bring full algorithm together<br>\n",
    "5.) Run tests with exemplary dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc50f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly as pl\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6232e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning and pre-preparation completed in EDA module\n",
    "df=pd.read_csv('data/ames_housing_price_data_prepared_v01.csv')\n",
    "df['SalePriceLog']=np.log10(df['SalePrice'])\n",
    "df=df.drop(['Unnamed: 0','SalePrice'],axis=1)\n",
    "\n",
    "#price=df['SalePrice']\n",
    "#price_log = np.log10(price)\n",
    "#df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067995f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb08b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d50c2f",
   "metadata": {},
   "source": [
    "<H1>Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f2d4e",
   "metadata": {},
   "source": [
    "'''\n",
    "keep: feature importance dictionary (key: feature, val: total RSS delta through feature split)\n",
    "keep: dataframe split into subtrees (through extra column identifying the subtree_id\n",
    "Input: (dictionary of used subtree_ids(increasing), including a tuple of splitting variable, splitting position, current maxdepth, subtree_id it was split from), same dict, but for unused subtrees, current RSS\n",
    "for each subtree\n",
    "    if not yet at maxdepth\n",
    "    check if split was searched before in unused subtree dict\n",
    "    for each feature\n",
    "        for each gap between two observations\n",
    "            divide tree into two subtrees\n",
    "            run linar regression on each subtree\n",
    "            save tuple: (feature, gapposition, RSS-delta)\n",
    "    find tuple with max RSS-delta, discard remaining tuples\n",
    "find remaining tuple with max RSS-delta\n",
    "split dataframe, update dictionaries, update feature importance dictionary with RSS delta\n",
    "if all subtrees at maxdepth: return RSS, (how to return splitting logic??)\n",
    "else: feed dataframes, RSS current-delta, list of maxdepth per subtree into next tree\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd42d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeBooster():\n",
    "    \n",
    "    def __init__(self, n_iter=20, n_iterations=10, learning_rate=0.1):\n",
    "        self.n_iter=n_iter\n",
    "        self.n_iterations=n_iterations\n",
    "        self.learning_rate=learning_rate\n",
    "        self.split_conditions={}\n",
    "        self.tree_means={}\n",
    "        \n",
    "    \n",
    "    def check_error(self,df):\n",
    "        mean=df['SalePriceLog'].mean()\n",
    "        error=sum(df['SalePriceLog'].apply(lambda x: (x-mean)**2))/df.shape[0]\n",
    "        return error\n",
    "\n",
    "    def treebuilder(self, df, tree_num=0):\n",
    "\n",
    "        df['subtree_id']=0\n",
    "        #feature_importance_dict={}\n",
    "        max_subtree_id=0\n",
    "\n",
    "        columns=list(df.columns)\n",
    "        columns.remove('subtree_id')\n",
    "        columns.pop()\n",
    "\n",
    "        tmp_dict={}\n",
    "        self.split_conditions[tree_num]={}\n",
    "        self.tree_means[tree_num]={}\n",
    "\n",
    "        k=0\n",
    "        while k<self.n_iter:\n",
    "\n",
    "            subtree_ids=df['subtree_id'].unique()\n",
    "\n",
    "            for subtree_id in subtree_ids: #each current subtree\n",
    "\n",
    "                for column in columns:#each feature\n",
    "\n",
    "                    if (subtree_id,column) not in tmp_dict:\n",
    "\n",
    "                        currentError=self.check_error(df[df['subtree_id']==subtree_id])\n",
    "\n",
    "                        split_values=list(df[df['subtree_id']==subtree_id][column].unique())\n",
    "                        split_values.sort()\n",
    "                        split_val=[]\n",
    "                        for i in range(1, len(split_values)):\n",
    "                            split_val.append(split_values[i-1]+(split_values[i]-split_values[i-1])/2)\n",
    "\n",
    "                        maxError=0\n",
    "                        for i in split_val:#each split\n",
    "\n",
    "                            newError=(self.check_error(df[(df['subtree_id']==subtree_id) & (df[column]<i)])*df[(df['subtree_id']==subtree_id) & (df[column]<i)].shape[0] + self.check_error(df[(df['subtree_id']==subtree_id) & (df[column]>=i)])*df[(df['subtree_id']==subtree_id) & (df[column]>=i)].shape[0])/df[(df['subtree_id']==subtree_id)].shape[0]\n",
    "\n",
    "                            deltaError=currentError-newError\n",
    "\n",
    "                            if deltaError>maxError:\n",
    "                                tmp_dict[(subtree_id,column)]=(i,deltaError)\n",
    "                                maxError=deltaError\n",
    "\n",
    "            #print(tmp_dict)\n",
    "            best_subtree_id, best_column=max(tmp_dict, key=lambda x: tmp_dict.get(x)[1])\n",
    "            best_split_pos=tmp_dict[(best_subtree_id, best_column)][0]\n",
    "            max_subtree_id+=1\n",
    "            df.loc[(df['subtree_id']==best_subtree_id) & (df[best_column]<best_split_pos),'subtree_id']=max_subtree_id\n",
    "            max_subtree_id+=1\n",
    "            df.loc[(df['subtree_id']==best_subtree_id)&(df[best_column]>=best_split_pos),'subtree_id']=max_subtree_id\n",
    "\n",
    "            for i,j in list(tmp_dict.keys()):\n",
    "                if i==best_subtree_id:\n",
    "                    del tmp_dict[(i,j)]   \n",
    "\n",
    "            k+=1\n",
    "            self.split_conditions[tree_num][best_subtree_id]=(best_column,best_split_pos,max_subtree_id-1,max_subtree_id)\n",
    "\n",
    "            #print(df['subtree_id'].value_counts())\n",
    "\n",
    "        \n",
    "        subtree_ids=df['subtree_id'].unique()\n",
    "        for subtree_id in subtree_ids: #each subtree\n",
    "            mean=df[df['subtree_id']==subtree_id]['SalePriceLog'].mean()\n",
    "            self.tree_means[tree_num][subtree_id]=mean\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def tree_predictor(self, df, tree_num=0):\n",
    "        \n",
    "        df['Predict']=0\n",
    "        for i in range(df.shape[0]):\n",
    "            current_subtree_id=0\n",
    "            while current_subtree_id not in self.tree_means[tree_num]:\n",
    "                column,split_pos,id_left,id_right = self.split_conditions[tree_num][current_subtree_id]\n",
    "                if df[column][i]<split_pos:\n",
    "                    current_subtree_id=id_left\n",
    "                else:\n",
    "                    current_subtree_id=id_right\n",
    "            df.loc[i,'Predict']=self.tree_means[tree_num][current_subtree_id]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def tree_scorer(self,df):\n",
    "        mean1=sum(df.iloc[:,0])/df.shape[0]\n",
    "        TSS=sum(df.iloc[:,0].map(lambda x: (x-mean1)**2))\n",
    "\n",
    "        RSS=sum((df.iloc[:,1]-df.iloc[:,0])**2)\n",
    "\n",
    "        return 1-RSS/TSS\n",
    "\n",
    "\n",
    "    def iteration_builder(self, df):\n",
    "        df2=df.copy()\n",
    "        for x in range(self.n_iterations):\n",
    "            df2=self.treebuilder(df2,tree_num=x)\n",
    "            df2=self.tree_predictor(df2,tree_num=x)\n",
    "            df2['SalePriceLog']=df2['SalePriceLog']+(df2['Predict']-df2['SalePriceLog'])*self.learning_rate\n",
    "            df2=df2.drop(['Predict'],axis=1)\n",
    "        return df2\n",
    "    \n",
    "    def iteration_predictor(self, df):\n",
    "\n",
    "        df['Predict_fin']=0\n",
    "        for x in range(n_iterations):\n",
    "            df=self.tree_predictor(df,tree_num=x)\n",
    "            df['Predict_fin']=df['Predict_fin']+self.learning_rate*df['Predict']\n",
    "            \n",
    "        df['Predict']=df['Predict_fin']\n",
    "        df=df.drop('Predict_fin',axis=1)\n",
    "\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cce2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "treemodel=TreeBooster(n_iter=20, n_iterations=10, learning_rate=0.3)\n",
    "df= treemodel.iteration_builder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "df2=treemodel.iteration_predictor(df2)\n",
    "treemodel.tree_scorer(df2[['SalePriceLog','Predict']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b14c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8163734050358602 at 20 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8377f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32    266\n",
       "35    255\n",
       "29    250\n",
       "39    193\n",
       "40    175\n",
       "17    171\n",
       "33    128\n",
       "28    112\n",
       "34    103\n",
       "36     96\n",
       "26     96\n",
       "31     93\n",
       "25     88\n",
       "20     81\n",
       "21     80\n",
       "22     51\n",
       "30     50\n",
       "27     48\n",
       "24     45\n",
       "37     41\n",
       "38     33\n",
       "Name: subtree_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['subtree_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
