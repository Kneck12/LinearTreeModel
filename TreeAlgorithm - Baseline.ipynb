{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d75e751",
   "metadata": {},
   "source": [
    "<H1>Linear Tree Algorithm experiment</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fefa4",
   "metadata": {},
   "source": [
    "1.) Collect, clean exemplary dataset for regression problem suited for linear tree model.<br>\n",
    "2.) Develop single tree algorithm with variables for depth, omitted features as input (others to be added later) and feature importance and classification solution as output<br>\n",
    "3.) Define simple Gradient Boosting algorithm<br>\n",
    "4.) Bring full algorithm together<br>\n",
    "5.) Run tests with exemplary dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7cc50f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly as pl\n",
    "import plotly.express as px\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6232e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning and pre-preparation completed in EDA module\n",
    "df=pd.read_csv('data/ames_housing_price_data_prepared_v01.csv')\n",
    "df['SalePriceLog']=np.log10(df['SalePrice'])\n",
    "df=df.drop(['Unnamed: 0','SalePrice'],axis=1)\n",
    "\n",
    "#price=df['SalePrice']\n",
    "#price_log = np.log10(price)\n",
    "#df.head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db2605e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlist=['GrLivArea', 'LotArea', 'OverallQual', 'BSMT_LowQual',\n",
    "       'house_age_years', 'GarageCars', 'FullBath', 'HalfBath',\n",
    "       'BsmtExposure_ord', 'SaleTypeNew', 'PorchSF', 'BSMT_HighQual',\n",
    "       'Fireplaces', 'Pool', 'BedroomAbvGr', 'SalePriceLog']\n",
    "df=df[columnlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d50c2f",
   "metadata": {},
   "source": [
    "<H1>Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f2d4e",
   "metadata": {},
   "source": [
    "'''\n",
    "keep: feature importance dictionary (key: feature, val: total RSS delta through feature split)\n",
    "keep: dataframe split into subtrees (through extra column identifying the subtree_id\n",
    "Input: (dictionary of used subtree_ids(increasing), including a tuple of splitting variable, splitting position, current maxdepth, subtree_id it was split from), same dict, but for unused subtrees, current RSS\n",
    "for each subtree\n",
    "    if not yet at maxdepth\n",
    "    check if split was searched before in unused subtree dict\n",
    "    for each feature\n",
    "        for each gap between two observations\n",
    "            divide tree into two subtrees\n",
    "            run linar regression on each subtree\n",
    "            save tuple: (feature, gapposition, RSS-delta)\n",
    "    find tuple with max RSS-delta, discard remaining tuples\n",
    "find remaining tuple with max RSS-delta\n",
    "split dataframe, update dictionaries, update feature importance dictionary with RSS delta\n",
    "if all subtrees at maxdepth: return RSS, (how to return splitting logic??)\n",
    "else: feed dataframes, RSS current-delta, list of maxdepth per subtree into next tree\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ebd42d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeBooster():\n",
    "    \n",
    "    def __init__(self, n_iter=16, n_iterations=10, learning_rate=0.1, max_depth=6, min_elements=1):\n",
    "        self.n_iter=n_iter\n",
    "        self.n_iterations=n_iterations\n",
    "        self.learning_rate=learning_rate\n",
    "        self.max_depth=max_depth\n",
    "        self.min_elements=min_elements\n",
    "        self.split_conditions={}\n",
    "        self.tree_means={}\n",
    "        self.tree_depth={}\n",
    "        self.columns=[]\n",
    "        \n",
    "        self.initial_mean=0\n",
    "        \n",
    "    \n",
    "    def check_error(self,df):\n",
    "        mean=df['Residuals'].mean()\n",
    "        error=sum(df['Residuals'].apply(lambda x: (x-mean)**2))/df.shape[0]\n",
    "        return error\n",
    "\n",
    "    def treebuilder(self, df, tree_num=0):\n",
    "\n",
    "        df['subtree_id']=0\n",
    "        #feature_importance_dict={}\n",
    "        max_subtree_id=0\n",
    "\n",
    "        tmp_dict={}\n",
    "        self.split_conditions[tree_num]={}\n",
    "        self.tree_means[tree_num]={}\n",
    "        self.tree_depth[tree_num]={}\n",
    "        \n",
    "        self.tree_depth[tree_num][0]=0\n",
    "\n",
    "        k=0\n",
    "        while k<self.n_iter:\n",
    "\n",
    "            subtree_ids=df['subtree_id'].unique()\n",
    "\n",
    "            for subtree_id in subtree_ids: #each current subtree\n",
    "                \n",
    "                if self.tree_depth[tree_num][subtree_id]<self.max_depth:\n",
    "\n",
    "                    for column in self.columns:#each feature\n",
    "\n",
    "                        if (subtree_id,column) not in tmp_dict:\n",
    "\n",
    "                            currentError=self.check_error(df[df['subtree_id']==subtree_id])\n",
    "\n",
    "                            split_values=list(df[df['subtree_id']==subtree_id][column].unique())\n",
    "                            split_values.sort()\n",
    "                            split_val=[]\n",
    "                            for i in range(1, len(split_values)):\n",
    "                                split_val.append(split_values[i-1]+(split_values[i]-split_values[i-1])/2)\n",
    "\n",
    "                            maxError=0\n",
    "                            for i in split_val:#each split\n",
    "                                \n",
    "                                bottom_shape=df[(df['subtree_id']==subtree_id) & (df[column]<i)].shape[0]\n",
    "                                top_shape=df[(df['subtree_id']==subtree_id) & (df[column]>=i)].shape[0]\n",
    "                                total_shape=df[(df['subtree_id']==subtree_id)].shape[0]\n",
    "                                \n",
    "                                if bottom_shape>=self.min_elements and top_shape>=self.min_elements:\n",
    "                                    newError=(self.check_error(df[(df['subtree_id']==subtree_id) & (df[column]<i)])*bottom_shape + self.check_error(df[(df['subtree_id']==subtree_id) & (df[column]>=i)])*top_shape)/total_shape\n",
    "\n",
    "                                    deltaError=currentError-newError\n",
    "\n",
    "                                    if deltaError>maxError:\n",
    "                                        tmp_dict[(subtree_id,column)]=(i,deltaError)\n",
    "                                        maxError=deltaError\n",
    "\n",
    "            #print(tmp_dict)\n",
    "            if tmp_dict:\n",
    "                best_subtree_id, best_column=max(tmp_dict, key=lambda x: tmp_dict.get(x)[1])\n",
    "                best_split_pos=tmp_dict[(best_subtree_id, best_column)][0]\n",
    "                max_subtree_id+=1\n",
    "                df.loc[(df['subtree_id']==best_subtree_id) & (df[best_column]<best_split_pos),'subtree_id']=max_subtree_id\n",
    "                self.tree_depth[tree_num][max_subtree_id]=self.tree_depth[tree_num][best_subtree_id]+1\n",
    "                max_subtree_id+=1\n",
    "                df.loc[(df['subtree_id']==best_subtree_id)&(df[best_column]>=best_split_pos),'subtree_id']=max_subtree_id\n",
    "                self.tree_depth[tree_num][max_subtree_id]=self.tree_depth[tree_num][best_subtree_id]+1\n",
    "\n",
    "                for i,j in list(tmp_dict.keys()):\n",
    "                    if i==best_subtree_id:\n",
    "                        del tmp_dict[(i,j)]   \n",
    "                        \n",
    "                        \n",
    "                self.split_conditions[tree_num][best_subtree_id]=(best_column,best_split_pos,max_subtree_id-1,max_subtree_id)\n",
    "            \n",
    "            k+=1\n",
    "            \n",
    "            #print(df['subtree_id'].value_counts())\n",
    "\n",
    "        \n",
    "        subtree_ids=df['subtree_id'].unique()\n",
    "        for subtree_id in subtree_ids: #each subtree\n",
    "            mean=df[df['subtree_id']==subtree_id]['Residuals'].mean()\n",
    "            self.tree_means[tree_num][subtree_id]=mean\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def tree_predictor(self, df, tree_num=0):\n",
    "        \n",
    "        df['Predict']=0\n",
    "        for i in df.index:\n",
    "            current_subtree_id=0\n",
    "            while current_subtree_id not in self.tree_means[tree_num]:\n",
    "                column,split_pos,id_left,id_right = self.split_conditions[tree_num][current_subtree_id]\n",
    "                if df[column][i]<split_pos:\n",
    "                    current_subtree_id=id_left\n",
    "                else:\n",
    "                    current_subtree_id=id_right\n",
    "            df.loc[i,'Predict']=self.tree_means[tree_num][current_subtree_id]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def tree_scorer(self,df):\n",
    "        mean1=sum(df.iloc[:,0])/df.shape[0]\n",
    "        TSS=sum(df.iloc[:,0].map(lambda x: (x-mean1)**2))\n",
    "\n",
    "        RSS=sum((df.iloc[:,1]-df.iloc[:,0])**2)\n",
    "\n",
    "        return 1-RSS/TSS\n",
    "\n",
    "\n",
    "    def iteration_builder(self, df):\n",
    "        df2=df.copy()\n",
    "        #df2.reset_index(drop=True)\n",
    "        \n",
    "        self.columns=list(df2.columns)\n",
    "        self.columns.pop()\n",
    "        \n",
    "        df2['Base_prediction']=df2['SalePriceLog'].mean()\n",
    "        self.initial_mean=df2['SalePriceLog'].mean()\n",
    "        df2['Residuals']=df2['SalePriceLog']-df2['Base_prediction']\n",
    "        \n",
    "        res_mean=df2['Residuals'].mean()\n",
    "        print(f'Starting; residual mean at {res_mean}')\n",
    "        \n",
    "        for x in range(self.n_iterations):\n",
    "            df2=self.treebuilder(df2,tree_num=x)\n",
    "            df2=self.tree_predictor(df2,tree_num=x)\n",
    "            df2['Base_prediction']=df2['Base_prediction']+df2['Predict']*self.learning_rate\n",
    "            df2['Residuals']=df2['SalePriceLog']-df2['Base_prediction']\n",
    "            df2=df2.drop(['Predict'],axis=1)\n",
    "            \n",
    "            res_mean=df2['Residuals'].mean()\n",
    "            print(f'Iteration {x} complete, residual mean at {res_mean}')\n",
    "        return df2\n",
    "    \n",
    "    def iteration_predictor(self, df):\n",
    "        \n",
    "        df2=df.copy()\n",
    "        df2=df2.reset_index(drop=False)\n",
    "\n",
    "        df2['Predict_fin']=self.initial_mean\n",
    "        for x in range(self.n_iterations):\n",
    "            df2=self.tree_predictor(df2,tree_num=x)\n",
    "            df2['Predict_fin']=df2['Predict_fin']+self.learning_rate*df2['Predict']\n",
    "            \n",
    "        df2['Predict']=df2['Predict_fin']\n",
    "        df2=df2.drop('Predict_fin',axis=1)\n",
    "        \n",
    "        df2=df2.set_index('index',drop=True)\n",
    "        df2.index.name=None\n",
    "\n",
    "        return df2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f8899fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices=list(np.random.choice(df.index, size=int(df.shape[0]*0.7),replace=False))\n",
    "test_indices=[x if x not in train_indices else -1 for x in df.index]\n",
    "df_train=df.loc[df.index.isin(train_indices)]\n",
    "df_test=df.loc[df.index.isin(test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "875368b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting; residual mean at 1.5782485911877428e-14\n",
      "Iteration 0 complete, residual mean at 1.253737768111044e-14\n",
      "Iteration 1 complete, residual mean at 1.0066194417916844e-14\n",
      "Iteration 2 complete, residual mean at 7.955348965276791e-15\n",
      "Iteration 3 complete, residual mean at 6.242064167322068e-15\n",
      "Iteration 4 complete, residual mean at 4.99044603339075e-15\n",
      "Iteration 5 complete, residual mean at 3.983878289993693e-15\n",
      "Iteration 6 complete, residual mean at 3.1236170033924078e-15\n",
      "Iteration 7 complete, residual mean at 2.57044418087836e-15\n",
      "Iteration 8 complete, residual mean at 2.1206681476192747e-15\n",
      "Iteration 9 complete, residual mean at 1.6093710247534865e-15\n",
      "Iteration 10 complete, residual mean at 1.2691955881046609e-15\n",
      "Iteration 11 complete, residual mean at 1.0179413902151027e-15\n",
      "Iteration 12 complete, residual mean at 8.4009891269656785e-16\n",
      "Iteration 13 complete, residual mean at 6.064221689803533e-16\n",
      "Iteration 14 complete, residual mean at 8.168346351142013e-16\n",
      "Iteration 15 complete, residual mean at 4.601157121845817e-16\n"
     ]
    }
   ],
   "source": [
    "treemodel=TreeBooster(n_iter=12, n_iterations=16, learning_rate=0.2, max_depth=4, min_elements=5)\n",
    "df_train= treemodel.iteration_builder(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5b97fc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929291835860964"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=df_test.reset_index(drop=False)\n",
    "df_test2=treemodel.iteration_predictor(df_test)\n",
    "treemodel.tree_scorer(df_test2[['SalePriceLog','Predict']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8929291835860964"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
